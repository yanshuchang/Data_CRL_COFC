CVPO

int cost_limit:                    The cost limit of the task. (1.50)
str device:                        The device to use for training ('cpu').
int seed:                          The random seed to use for training. (10)
int estep_iter_num:                The number of iterations for the E-step. (1)
float estep_kl:                    The KL divergence threshold for the E-step. (0.02)
float estep_dual_max:              The maximum value for the dual variable in the E-step. (20)
float estep_dual_lr:               The learning rate for the dual variable in the E-step. (0.02)
sample_act_num:                    The number of actions to sample for the E-step. (64)
int mstep_iter_num:                The number of iterations for the M-step. (1)
float mstep_kl_mu:                 The KL divergence threshold for the M-step (mean). (0.005)
float mstep_kl_std:                The KL divergence threshold for the M-step (standard deviation). (0.0005)
float mstep_dual_max:              The maximum value for the dual variable in the M-step. (0.5)
float mstep_dual_lr:               The learning rate for the dual variable in the M-step. (0.1)
float actor_lr:                    The learning rate of the actor network. (5e-4)
float critic_lr:                   The learning rate of the critic network. (1e-3)
float gamma:                       The discount factor. (0.98)
int n_step:                        The number of steps to look ahead when computing returns. (2)
float tau:                         The critics soft update coefficient. (0.05)
Tuple[int, ...] hidden_sizes:      The sizes of the hidden layers in the actor and critic networks. ([128, 128])
bool double_critic:                Whether to use two critic networks instead of one. (False)
bool conditioned_sigma:            Whether the variance of the Gaussian policy is conditioned on the state. (True)
bool unbounded:                    Whether to use an unbounded output layer for the actor network. (False)
bool last_layer_scale:             Whether to scale the last layer of the actor network. (False)
bool deterministic_eval:           Whether to use a deterministic policy during evaluation. (True)
bool action_scaling:               Whether to scale actions by the maximum action value. (True)
str action_bound_method:           The method to use for action bounds ('clip' or 'tanh'). ('clip')
torch.optim.lr_scheduler.LambdaLR: The learning rate scheduler. (None)
